---
title: |
  | STATS/CSE 780
  | Assignment 2
author: "Pao Zhu Vivian Hsu (Student Number: 400547994)"
date: "`r format(Sys.time(), '%d %B, %Y')`"
format: pdf
editor: visual
execute:
  echo: false
  warning: false
  error: false
header-includes:
  - \usepackage{float}
  - \floatplacement{figure}{H}
bibliography: A2.bib
csl: https://www.zotero.org/styles/apa-single-spaced
nocite: |
  @xie2020r
fontsize: 11pt
geometry: 
  - margin = 1in
linestretch: 1.5
---

\newpage

```{r setup}
# ----- LOAD PACKAGES AND DATA ----- #

library(dplyr)
library(tidyverse)
library(DescTools)
library(ggplot2)
library(class)
library(pROC)

bank_raw <- read.csv("Churn_Modelling.csv")


```

```{r exp-clean}
# ----- DATA EXPLORATION ----- #

# Check dimensions of data
dim(bank_raw)

# Check data types to see if they make logical sense
lapply(bank_raw,class)
bank_raw$Age[round(bank_raw$Age) != bank_raw$Age] # There are ages that are decimals

# Check for outliers / data that doesn't make sense logically
min(bank_raw$Age, na.rm = TRUE)
min(bank_raw$Tenure, na.rm = TRUE)
min(bank_raw$NumOfProducts, na.rm = TRUE)
min(bank_raw$EstimatedSalary, na.rm = TRUE)
max(bank_raw$Age, na.rm = TRUE)
max(bank_raw$Tenure, na.rm = TRUE)
max(bank_raw$NumOfProducts, na.rm = TRUE)
max(bank_raw$EstimatedSalary, na.rm = TRUE)

# Check for missing values
sapply(bank_raw, function(col){sum(is.na(col))}) # Null values
sapply(bank_raw, function(col){sum(col == "")}) # Blank values


# ----- CLEAN DATA ----- #

bank <- bank_raw %>%
  
  # Remove columns that are not important for analysis
  select(-c("RowNumber", "CustomerId", "Surname")) %>%
  
  # Impute missing values with mean, median, and mode
  mutate(Age = replace_na(Age, round(mean(Age,na.rm=TRUE),0)),
         HasCrCard = replace_na(HasCrCard, median(HasCrCard,na.rm=TRUE)),
         IsActiveMember = replace_na(IsActiveMember, median(HasCrCard,na.rm=TRUE)),
         Geography = ifelse(Geography == "", Mode(Geography,na.rm=TRUE)[1], Geography)
         ) %>% 
  
  # Change data types
  mutate(Age = as.integer(round(Age)),
         Geography = unclass(as.factor(Geography)),
         Gender = unclass(as.factor(Gender)),
         HasCrCard = as.factor(HasCrCard),
         IsActiveMember = as.factor(IsActiveMember),
         Exited = as.factor(Exited)
         )


```


```{r visuals}
# ----- DATA VISUALIZATION  ----- #
# Create a boxplot for each continuous variable 
ggplot(bank, aes(x = Exited, y = CreditScore)) + geom_boxplot()
ggplot(bank, aes(x = Exited, y = Age)) + geom_boxplot()
ggplot(bank, aes(x = Exited, y = Tenure)) + geom_boxplot()
ggplot(bank, aes(x = Exited, y = Balance)) + geom_boxplot()
ggplot(bank, aes(x = Exited, y = NumOfProducts)) + geom_boxplot()
ggplot(bank, aes(x = Exited, y = EstimatedSalary)) + geom_boxplot()

# Create bar charts for categorical variables
ggplot(bank, aes(x = HasCrCard, fill = Exited)) + geom_bar(position = "dodge")
ggplot(bank, aes(x = IsActiveMember, fill = Exited)) + geom_bar(position = "dodge")
ggplot(bank, aes(x = Geography, fill = Exited)) + geom_bar(position = "dodge")
ggplot(bank, aes(x = Gender, fill = Exited)) + geom_bar(position = "dodge")

# Check if there's correlation between variables
corr_matrix <- round(cor(bank %>% dplyr::select(-1, -2, -11)), 3)
ggcorrplot(corr_matrix, hc.order = TRUE, lab = TRUE)


```

```{r split}
# ----- SPLIT INTO TRAIN & TEST DATA ----- #

set.seed(2023780)
train_index <- sample(1:nrow(bank), round(nrow(bank)/2, 0), replace = FALSE)

# Training set
train_data <- bank[train_index, ]
train_x <- dplyr::select(train_data, -Exited)
train_y <- dplyr::pull(train_data, Exited)

# Testing set
test_data <- bank[-train_index, ]
test_x <- dplyr::select(test_data, -Exited)
test_y <- dplyr::pull(test_data, Exited)


```

```{r log-reg}
# ----- LOGISTIC REGRESSION ----- #

set.seed(2023780)

# Include all variables as predictors in the regression
log_mod1 <- glm(Exited ~ .,
                family = binomial("logit"), data = train_data)
summary(log_mod1)

# Remove predictors with p-values that are not significant (i.e. > 0.05)
log_mod1 <- update(log_mod1, ~ . -CreditScore -Tenure -NumOfProducts 
                   -HasCrCard -EstimatedSalary -Geography)
summary(log_mod1)

# Predict outcome using test set
log_mod1_y_prob <- predict(log_mod1, newdata = test_data, type = "response") # y probabilities


```

```{r knn-class}
# ----- K-NEAREST NEIGHBOUR CLASSIFICATION ----- #

set.seed(2023780)

# Develop KNN model and predict outcome using test set
knn_mod1_y <- knn(train=train_x, test=test_x, cl=train_y, k=2) 


```

```{r performance}
# ----- CLASSIFIER PERFORMANCE ----- #

# --- LOGISTIC REGRESSION MODEL PERFORMANCE --- #
# Find the optimal cut-off value using ROC curve
log_mod1_pROC <- roc(test_y, log_mod1_y_prob, smoothed = TRUE, ci=TRUE, ci.alpha=0.9, 
                     plot=TRUE, auc.polygon=TRUE, max.auc.polygon=TRUE, grid=TRUE,
                     print.auc=TRUE, show.thres=TRUE)
cutoff <- coords(log_mod1_pROC, "best")$threshold

# Assign labels to prediction results using cut-off value
log_mod1_y <- ifelse(log_mod1_y_prob > cutoff, 1, 0)

# Stats on model performance
log_mod1_cmatrix <- table(log_mod1_y, test_y) # Confusion matrix
log_mod1_cmatrix
mean(log_mod1_y != test_y) # Miss-classification error rate (% of churn incorrectly predicted)
mean(log_mod1_y == test_y) # Accuracy (% of churn correctly predicted)
log_mod1_cmatrix[2,2]/sum(log_mod1_cmatrix[2,]) # Sensitivity (% correctly predicted as churned)
log_mod1_cmatrix[1,1]/sum(log_mod1_cmatrix[1,]) # Specificity (% correctly predicted as not churned)

# --- KNN MODEL PERFORMANCE --- #
# Stats on model performance
knn_mod1_cmatrix <- table(knn_mod1_y, test_y) # Confusion matrix
knn_mod1_cmatrix
mean(knn_mod1_y != test_y) # Miss-classification error rate (% of churn incorrectly predicted)
mean(knn_mod1_y == test_y) # Accuracy (% of churn correctly predicted)
knn_mod1_cmatrix[2,2]/sum(knn_mod1_cmatrix[2,]) # Sensitivity (% correctly predicted as churned)
knn_mod1_cmatrix[1,1]/sum(knn_mod1_cmatrix[1,]) # Specificity (% correctly predicted as not churned)


```

```{r ridge-reg}
# ----- LOGISTIC REGRESSION WITH SHRINKAGE ----- #

set.seed(2023780)


```



## Introduction

The goal of this study is to predict customer churn at a bank. 

## Methods

Data involving a bank's customers and churn was downloaded from Kaggle [@bankData]. The original data set consisted of 14 variables and about 10,000 rows of observations. This data was selected because it includes a binary variable indicating customer churn status that is suitable for the purpose of logistic regression and K-nearest neighbour classification. It also contained a variety of variables describing the customer such as estimated salary, age, bank balance, and more. Row numbers, customer ids, and surnames were removed from the data set because they are not important for the purpose of studying customer churn. Based on Harrell's 1:15 rule of choosing predictor variables with respect to sample size [-@Harrell], the remaining 10 variables were used as predictor variables for classification. A full description of each variable along with their data types can be found in the Supplementary Materials section [@bankData].



## Results



## Discussion



\newpage

## Supplementary material

### Data Description

### Code
```{r code, ref.label=knitr::all_labels(), echo=TRUE, eval=FALSE}
```

\newpage

## References

::: {#refs}
:::
